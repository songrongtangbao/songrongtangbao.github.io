import{_ as e,c as t,o as r,ai as s}from"./chunks/framework.DAKf9Ncm.js";const o="/assets/000229.D7yIfv48.png",l="/assets/000820.CKn3hSjc.png",u=JSON.parse('{"title":"deepseek本地部署","description":"","frontmatter":{"title":"deepseek本地部署","prev":false,"next":false},"headers":[],"relativePath":"software/deepseek/index.md","filePath":"software/deepseek/index.md","lastUpdated":1739117428000}'),n={name:"software/deepseek/index.md"};function i(p,a,d,h,c,b){return r(),t("div",null,[...a[0]||(a[0]=[s('<h1 id="deepseek本地部署" tabindex="-1">deepseek本地部署 <a class="header-anchor" href="#deepseek本地部署" aria-label="Permalink to &quot;deepseek本地部署&quot;">​</a></h1><h2 id="安装ollama" tabindex="-1">安装ollama <a class="header-anchor" href="#安装ollama" aria-label="Permalink to &quot;安装ollama&quot;">​</a></h2><h3 id="安装" tabindex="-1">安装 <a class="header-anchor" href="#安装" aria-label="Permalink to &quot;安装&quot;">​</a></h3><p><a href="https://ollama.com/" target="_blank" rel="noreferrer">ollama官网</a></p><p>下载安装一路点点点。</p><h3 id="安装位置" tabindex="-1">安装位置 <a class="header-anchor" href="#安装位置" aria-label="Permalink to &quot;安装位置&quot;">​</a></h3><p>默认安装在C盘，如需修改到其他盘，可以在<code>C:\\Users\\用户名\\AppData\\Local\\Programs</code>文件夹中将<code>Ollama</code>迁移到其他位置。</p><p>迁移完成后，在环境变量中的用户变量的<code>Path</code>中，将原文件夹路径更改为迁移后的路径。</p><h3 id="模型位置" tabindex="-1">模型位置 <a class="header-anchor" href="#模型位置" aria-label="Permalink to &quot;模型位置&quot;">​</a></h3><p>在环境变量的系统变量中设置变量名<code>OLLAMA_MODELS</code>，值为要存放模型的文件夹路径。</p><h2 id="安装chatbox" tabindex="-1">安装chatbox <a class="header-anchor" href="#安装chatbox" aria-label="Permalink to &quot;安装chatbox&quot;">​</a></h2><p><a href="https://chatboxai.app/" target="_blank" rel="noreferrer">chatbox官网</a></p><p>下载安装包一路点点点。</p><h2 id="配置" tabindex="-1">配置 <a class="header-anchor" href="#配置" aria-label="Permalink to &quot;配置&quot;">​</a></h2><h3 id="ollama" tabindex="-1">ollama <a class="header-anchor" href="#ollama" aria-label="Permalink to &quot;ollama&quot;">​</a></h3><p>访问<a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noreferrer">ollama的deepseek模型网址</a></p><p>选择合适的模型大小，然后复制代码，位置如图所示</p><p><img src="'+o+'" alt="示例"></p><p>在终端运行</p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>ollama run deepseek-r1:14b</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>完成后已经在终端可用，输入</p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>/bye</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>结束对话。</p><h3 id="chatbox" tabindex="-1">chatbox <a class="header-anchor" href="#chatbox" aria-label="Permalink to &quot;chatbox&quot;">​</a></h3><p>打开chatbox，选择本地模型，模型提供方选择<code>OLLAMA API</code>，上下文的消息数量上限选择不限制，点击保存。</p><h2 id="完工" tabindex="-1">完工 <a class="header-anchor" href="#完工" aria-label="Permalink to &quot;完工&quot;">​</a></h2><p>完工截图</p><p><img src="'+l+'" alt="完工截图"></p>',28)])])}const k=e(n,[["render",i]]);export{u as __pageData,k as default};
